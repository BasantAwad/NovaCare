{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Text Emotion Training - RoBERTa on GoEmotions\n",
    "\n",
    "Train RoBERTa for text emotion classification. Run in Google Colab with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification, \n    TrainingArguments, \n    Trainer,\n    DataCollatorWithPadding\n)\nfrom sklearn.metrics import accuracy_score, f1_score\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GoEmotions\ndataset = load_dataset('go_emotions', 'simplified')\nEMOTION_LABELS = ['admiration','amusement','anger','annoyance','approval','caring','confusion','curiosity','desire','disappointment','disapproval','disgust','embarrassment','excitement','fear','gratitude','grief','joy','love','nervousness','optimism','pride','realization','relief','remorse','sadness','surprise','neutral']\n\n# Convert multi-label to single-label (use first label)\ndef preprocess(ex):\n    ex['label'] = ex['labels'][0] if ex['labels'] else 27\n    return ex\n\ndataset = dataset.map(preprocess)\nprint(f\"Train: {len(dataset['train'])}, Val: {len(dataset['validation'])}, Test: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model\nMODEL = 'roberta-base'\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL, \n    num_labels=28,\n    id2label={i: l for i, l in enumerate(EMOTION_LABELS)},\n    label2id={l: i for i, l in enumerate(EMOTION_LABELS)}\n)\n\nprint(f'Model loaded: {MODEL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize dataset - DO NOT pad here, let data collator handle it\ndef tokenize(examples):\n    return tokenizer(\n        examples['text'], \n        truncation=True, \n        max_length=128\n        # NO padding='max_length' here!\n    )\n\ntokenized = dataset.map(tokenize, batched=True, remove_columns=['text', 'labels', 'id'])\nprint('Tokenization complete!')\nprint(f\"Columns: {tokenized['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator for dynamic padding (THIS FIXES THE ERROR!)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Metrics function\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n    return {\n        'accuracy': accuracy_score(p.label_ids, preds), \n        'f1': f1_score(p.label_ids, preds, average='weighted')\n    }\n\nprint('Data collator ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\nargs = TrainingArguments(\n    output_dir='./roberta_text',\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=32,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_steps=100,\n    eval_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    fp16=torch.cuda.is_available(),\n    report_to='none'\n)\n\n# Initialize trainer with data_collator\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized['train'],\n    eval_dataset=tokenized['validation'],\n    tokenizer=tokenizer,\n    data_collator=data_collator,  # THIS IS CRITICAL!\n    compute_metrics=compute_metrics\n)\n\nprint('Trainer ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\nprint('Starting training...')\ntrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\nprint('Evaluating on test set...')\nresults = trainer.evaluate(tokenized['test'])\nprint(f\"Test Accuracy: {results['eval_accuracy']:.4f}\")\nprint(f\"Test F1: {results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to Google Drive\nimport os\nSAVE_PATH = '/content/drive/MyDrive/models/roberta_text'\nos.makedirs(SAVE_PATH, exist_ok=True)\n\ntrainer.save_model(SAVE_PATH)\ntokenizer.save_pretrained(SAVE_PATH)\nprint(f'Model saved to {SAVE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test\nfrom transformers import pipeline\n\nclassifier = pipeline('text-classification', model=SAVE_PATH, top_k=3)\n\ntest_texts = [\n    \"I'm so happy today!\",\n    \"This is absolutely terrible.\",\n    \"Thank you for your help!\"\n]\n\nprint('\\nTest Predictions:')\nfor text in test_texts:\n    result = classifier(text)\n    print(f'\\n\"{text}\"')\n    for r in result[0]:\n        print(f\"  {r['label']}: {r['score']:.3f}\")"
   ]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
